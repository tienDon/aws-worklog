---
title: "Event 3"
date: 2025-11-15T08:30:18+07:00
draft: true
---
{{% notice warning %}}
⚠️ **Note:** The content below is rewritten for reference. Please **do not copy it verbatim** into your final report.
{{% /notice %}}

# Summary Report: “AI/ML/GenAI on AWS – Workshop for Intern Students”

### Event Objectives
- Provide a comprehensive overview of AI, Machine Learning (ML), and Generative AI (GenAI) on AWS for intern students.  
- Introduce AWS services supporting the entire ML lifecycle: data preparation, model training, deployment, and monitoring.  
- Guide techniques in Generative AI, Prompt Engineering, and RAG (Retrieval-Augmented Generation).  
- Encourage hands-on practice, experience sharing, and networking between students and AWS experts.  
- Help students apply knowledge to internship projects or personal research, enhancing technical skills.  

### Speakers
-  

---

## Key Highlights

### 8:30 – 9:00 AM | Welcome & Introduction
- Participant registration and networking with other students.  
- Overview of the workshop content, learning objectives, and hands-on guidelines.  
- Ice-breaker activities to facilitate interaction and create a collaborative learning environment.  
- Overview of the AI/ML landscape in Vietnam: career opportunities, real-world applications, and common challenges faced by interns.  

### 9:00 – 10:30 AM | AWS AI/ML Services Overview
- **Amazon SageMaker**: End-to-end ML platform for data preparation, model training, tuning, and deployment.  
- **Data preparation & labeling**: Standardizing data, handling missing values, and labeling for supervised learning.  
- **Model training & tuning**: Training models, hyperparameter optimization, and performance evaluation.  
- **Deployment & MLOps**: Deploying models to AWS, monitoring performance, and automating model updates.  
- **Live Demo:** Walkthrough SageMaker Studio – upload datasets, train a model, deploy, and test.  

### 10:30 – 10:45 AM | Coffee Break
- Networking, discussion, and casual interaction with mentors and other participants.  

### 10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock
- **Foundation Models**: Comparison of Claude, Llama, and Titan regarding language generation, knowledge integration, speed, and cost.  
- **Prompt Engineering**: Techniques for creating effective prompts, Chain-of-Thought reasoning, and Few-shot learning.  
- **Retrieval-Augmented Generation (RAG)**: Integrating GenAI with knowledge bases to generate responses based on specific data.  
- **Bedrock Agents**: Designing multi-step automated workflows combining multiple tools for complex tasks.  
- **Guardrails**: Implementing safety measures to control content and prevent inappropriate outputs.  
- **Live Demo:** Building a Generative AI chatbot using Bedrock, demonstrating prompt creation, RAG integration, and guardrails in practice.  

---

## Key Takeaways

### AI/ML & GenAI Knowledge
- AWS provides a comprehensive solution for the entire ML lifecycle from **data preparation**, **training**, **deployment**, to **monitoring**.  
- SageMaker allows interns to experience end-to-end ML workflow from raw data to deployable models.  
- Amazon Bedrock enables Generative AI with foundation models, multi-step agents, and RAG.  
- Prompt Engineering is crucial for generating accurate and relevant output.  
- Guardrails ensure safety and compliance, teaching students how to deploy AI/ML responsibly.  

### Applying to Internship Projects
- Deploy basic or advanced ML models using SageMaker for internship projects.  
- Build Generative AI chatbots or applications using Amazon Bedrock.  
- Integrate RAG to allow AI to answer questions using internal datasets.  
- Practice prompt engineering to improve AI output quality.  
- Set up guardrails to maintain content safety and quality.  

### Learning Experience
- Hands-on practice helps students understand ML/GenAI workflows, deployment, and operations.  
- Live demos illustrate integration of foundation models, RAG, agents, and prompt engineering.  
- Workshop encourages interaction, networking, and knowledge sharing with AWS experts and peers.  

### General Lessons
- Understanding the ML/GenAI lifecycle from data to deployment is essential.  
- Prompt engineering and workflow management are key skills for building effective Generative AI applications.  
- Using AWS tools increases productivity, reduces deployment time, and ensures safe AI outputs.  

---

## Applying to Work / Internship
- Implement ML models on SageMaker to practice end-to-end workflow.  
- Experiment with building GenAI chatbots using Bedrock for group or individual projects.  
- Design RAG integration for chatbots to answer questions based on specific knowledge.  
- Write effective prompts, analyze outputs, and continuously improve results.  
- Learn to implement guardrails for safe, controlled AI behavior.  

---

## Event Experience
- Interns gained practical exposure to AI/ML/GenAI workflows from experts.  
- Live demonstrations provided clear guidance on deploying, training, and monitoring models.  
- The workshop combined theory and practice, enhancing technical skills and fostering networking opportunities.  

---

### Event Photos  
*Insert your event photos here*  

> This event significantly enhanced intern students’ understanding and practical skills in AI/ML/GenAI on AWS, covering everything from foundational concepts to hands-on deployment, while providing networking opportunities with experts and peers.